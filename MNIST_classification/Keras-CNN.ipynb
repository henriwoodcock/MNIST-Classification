{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks - MNIST Dataset\n",
    "\n",
    "Convolutional neural networks have been shown to be very successful in image recognition. A MLP is fully connected by each layer, for an image this can result in a huge ammount of weights to be learned, especially if the imagine is RGB you have 3x the amount of pixels. This can result in huge amounts of weights to learn.\n",
    "\n",
    "On the other hand a convolutional neural net will use a \"filter\" to scan the images. This is essentially looking over smaller portions of an image so maybe a 3x3 section of the picture. This allows for nearby pixels to be more strongly related than further away pixels, this means the model learns relationships between certain parts of images for example the shape of an eye when recognising a face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12b306be0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "i = random.randint(1,60000)\n",
    "plt.imshow(x_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\n",
    "input_shape = (1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.fit(x_train, y_train, \n",
    "          #batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_input to have shape (28, 28, 1) but got array with shape (1, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fe1913bff5f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2380\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0;34m'Error when checking '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_input to have shape (28, 28, 1) but got array with shape (1, 28, 28)"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size= 32 ,epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
